{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input training and testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "X = np.load('./Data/Closing_Price.npy')\n",
    "Y = np.load('./Data/Trading_Volume.npy')\n",
    "Day_Split = 300\n",
    "# X_Train:(496, 300), Y_Train:(1, 300), X_Test:(496, 165), Y_Test:(1, 165)\n",
    "X_Train, X_Test = X[:, :Day_Split], X[:, Day_Split:]\n",
    "Y_Train, Y_Test = Y[:, :Day_Split], Y[:, Day_Split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_mu = np.mean(X_Train, axis=1, keepdims=True)\n",
    "X_Train_sigma = np.std(X_Train, axis=1, keepdims=True)\n",
    "Y_Train_mu = np.mean(Y_Train, axis=1)\n",
    "Y_Train_sigma = np.std(Y_Train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data output as 2 csv FILE for C++\n",
    "X_Test_Scaled = (X_Test - X_Train_mu) / X_Train_sigma\n",
    "Y_Test_Scaled = (Y_Test - Y_Train_mu) / Y_Train_sigma\n",
    "np.savetxt('X_Test_Scaled.csv', X_Test_Scaled, delimiter=\",\")\n",
    "np.savetxt('Y_Test_Scaled.csv', Y_Test_Scaled, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a three-layer neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "training_epochs = 500\n",
    "# number of training examples\n",
    "m = X_Train.shape[1]\n",
    "# number of neurons in the input layer\n",
    "n_input = X_Train.shape[0]\n",
    "# number of neurons in layer 1\n",
    "n_hidden_1 = 50\n",
    "# number of neurons in layer 2\n",
    "n_hidden_2 = 5\n",
    "# number of neurons in layer 3\n",
    "n_hidden_3 = 1\n",
    "#Initialization Weights Matrix W and Bias b\n",
    "W1 = np.random.randn(n_hidden_1, n_input) * 0.1\n",
    "W2 = np.random.randn(n_hidden_2, n_hidden_1) * 0.1\n",
    "W3 = np.random.randn(n_hidden_3, n_hidden_2) * 0.1\n",
    "b1 = np.zeros((n_hidden_1, 1))\n",
    "b2 = np.zeros((n_hidden_2, 1))\n",
    "b3 = np.zeros((n_hidden_3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Relu(z):\n",
    "    z[z<=0.0] = 0.0\n",
    "    return z\n",
    "\n",
    "def Relu_prime(z):\n",
    "    x = np.zeros(z.shape)\n",
    "    x[z>0] = 1\n",
    "    x[z==0] = 0.5\n",
    "    return x\n",
    "\n",
    "def Cost_Function(y_predict, y):\n",
    "    cost = (y_predict-y)**2\n",
    "    cost = sum(cost[0])/y.shape[1]\n",
    "    return cost\n",
    "\n",
    "def np_dot(A, B):\n",
    "    # C = np.dot(A, B)\n",
    "    C = np.zeros((A.shape[0], B.shape[1]))\n",
    "    # iterating by row of A \n",
    "    for i in range(len(A)): \n",
    "        # iterating by coloum by B  \n",
    "        for j in range(len(B[0])): \n",
    "            # iterating by rows of B \n",
    "            for k in range(len(B)): \n",
    "                C[i][j] += A[i][k] * B[k][j]\n",
    "    return C\n",
    "\n",
    "def np_sum(A):\n",
    "    B = np.zeros((len(A), 1))\n",
    "    for i in range(len(A)):\n",
    "        B[i][0] = sum(A[i])\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Three_Layer_Network_Training(X_Train, Y_Train, W1, W2, W3, b1, b2, b3, learning_rate=0.005):\n",
    "    # Forward Propagation Algorithm\n",
    "    m = X_Train.shape[1]\n",
    "    A0 = X_Train\n",
    "    Z1 = np_dot(W1, A0) + b1\n",
    "    A1 = Relu(Z1)\n",
    "    Z2 = np_dot(W2, A1) + b2\n",
    "    A2 = Relu(Z2)\n",
    "    Z3 = np_dot(W3, A2) + b3\n",
    "    A3 = Relu(Z3)\n",
    "    Fx = Cost_Function(A3, Y_Train)\n",
    "\n",
    "    # Backward Propagation Algorithm\n",
    "    dZ3 = 2 * (A3-Y_Train) * Relu_prime(Z3)\n",
    "    dW3 = np_dot(dZ3, A2.T) / m\n",
    "    db3 = np_sum(dZ3) / m\n",
    "    dA2 = np_dot(W3.T, dZ3)\n",
    "\n",
    "    dZ2 = dA2 * Relu_prime(Z2)\n",
    "    dW2 = np_dot(dZ2, A1.T) / m\n",
    "    db2 = np_sum(dZ2) / m\n",
    "    dA1 = np_dot(W2.T, dZ2)\n",
    "\n",
    "    dZ1 = dA1 * Relu_prime(Z1)\n",
    "    dW1 = np_dot(dZ1, A0.T) / m\n",
    "    db1 = np_sum(dZ1) / m\n",
    "\n",
    "    # Gradient Descent\n",
    "    W1 = W1 - learning_rate*dW1\n",
    "    W2 = W2 - learning_rate*dW2\n",
    "    W3 = W3 - learning_rate*dW3\n",
    "    b1 = b1 - learning_rate*db1\n",
    "    b2 = b2 - learning_rate*db2\n",
    "    b3 = b3 - learning_rate*db3\n",
    "    return W1, W2, W3, b1, b2, b3, Fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Scaling\n",
    "X_Train_Scaled = (X_Train - X_Train_mu) / X_Train_sigma\n",
    "Y_Train_Scaled = (Y_Train - Y_Train_mu) / Y_Train_sigma\n",
    "\n",
    "# Minimize Cost Function\n",
    "Fx_array = np.zeros(training_epochs)\n",
    "for iterations in range(training_epochs):\n",
    "    W1, W2, W3, b1, b2, b3, Fx_array[iterations] = Three_Layer_Network_Training(X_Train_Scaled, Y_Train_Scaled, W1, W2, W3, b1, b2, b3)\n",
    "    if iterations%10 == 0:\n",
    "        print(\"%d iterations cost is: %.9f\" % (iterations, Fx_array[iterations]))\n",
    "\n",
    "# Plot the Graph\n",
    "plt.plot(range(training_epochs), Fx_array, 'g-', linewidth=2.0)\n",
    "plt.title('Gradient Descent')\n",
    "plt.xlabel('Number of Iterations')\n",
    "plt.ylabel('Cost Function')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict the next day trading volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Predict_Function(X_Test, Y_Test, W1, W2, W3, b1, b2, b3):\n",
    "    # Forward Propagation Algorithm\n",
    "    A0 = X_Test\n",
    "    Z1 = np_dot(W1, A0) + b1\n",
    "    A1 = Relu(Z1)\n",
    "    Z2 = np_dot(W2, A1) + b2\n",
    "    A2 = Relu(Z2)\n",
    "    Z3 = np_dot(W3, A2) + b3\n",
    "    A3 = Relu(Z3)\n",
    "    Y_Predict = A3\n",
    "    Fx = Cost_Function(Y_Predict, Y_Test)\n",
    "    print(\"The Test Cost is:\", Fx)\n",
    "    return Y_Predict, Fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Scaling\n",
    "X_Test_Scaled = (X_Test - X_Train_mu) / X_Train_sigma\n",
    "Y_Test_Scaled = (Y_Test - Y_Train_mu) / Y_Train_sigma\n",
    "Y_Test_Hat = Predict_Function(X_Test_Scaled, Y_Test_Scaled, W1, W2, W3, b1, b2, b3)\n",
    "\n",
    "# Scaled Back\n",
    "Y_Test_Real = Y_Test_Hat * Y_Train_sigma + Y_Train_mu\n",
    "\n",
    "# Plot the Graph\n",
    "plt.plot(range(Y_Test_Hat.shape[1]), np.squeeze(Y_Test_Hat), 'm-', label='Predict')\n",
    "plt.plot(range(Y_Test_Scaled.shape[1]), np.squeeze(Y_Test_Scaled), 'b-', label='Real')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Trading Volume')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
